---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an assistant professor in the [CSE department](https://cse.osu.edu/) at The Ohio State University and a part-time research scientist at [Yahoo! Research](https://research.yahoo.com/). My research interest is in theoretical and applied machine learning with fairness and privacy guarantees, robust machine learning, distributed learning, and efficient machine learning for tiny devices. 

Current Graduate Students
======
[Zhiqun Zuo](https://www.linkedin.com/in/zhiqun-zuo-616507277/) (**Research Project:** Causal Fairness, Counterfactual Reasoning for Fair Machine Learning)

Zhongteng Cai (**Research Project:** Privacy-Aware Model Compression and Quantization)

Ding Zhu (**Research Project:** Trustworthy Model Compression, Time Series Data Analysis Using Foundation Models)

Vishnu Chhabra (**Research Project:** Mechanistic Interpretability for Foundation Models)


Recent News
======

**2024**

* Received a GPU server for the lab.
  
* Invited to give a talk on **Counterfactual Reseaning for Fair Machine Learning** at [the Midwest Machine Learning Symposium](https://midwest-ml.org/2024/).

* Zhongteng Cai received a travel grant to attend the UAI conference and present his work. 

* New paper titled "[Privacy-Aware Randomized Quantization via Linear Programming](https://khalilimahdi.github.io/)" is accepted in the 40th Conference on Uncertainty in Artificial Intelligence (UAI). 

* Received a grant from the Translational Data Analytics Institute to build interpretable and efficient AI models for medical diagnosis.

* New PhD student, Vishnu Chhabra joined my lab. He will be working on Mechanistic Interpretability for foundation models. 

* New paper titled "[Imposing Fairness Constraints in Synthetic Data Generation](https://khalilimahdi.github.io/)" is accepted in the 27th International Conference on Artificial Intelligence and Statistics (AISTATS). 

* Received a grant from the college of engineering to build safe, robust, and interpretable AI models for large-scale systems. 

**2023**

* New paper titled "[Counterfactually Fair Representation](https://arxiv.org/pdf/2311.05420.pdf)" is accepted in the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS). 

* New paper titled "[Loss Balancing for Fair Supervised Learning](https://openreview.net/pdf?id=gVGZyRDpXX)" is accepted in the International Conference of Machine Learning (ICML). 

* New paper titled "[Symbolic Metamodels for Interpreting Black-boxes Using Primitive Functions]()" is accepted (for oral presentation) in the AAAI Conference on Artificial Intelligence.

* New paper titled "[Counterfactual Fairness in Synthetic Data Generation](https://openreview.net/pdf?id=tge5NiX4CZo)" is accepted in the Neurips workshop on Synthetic Data for Machine Learning. 

* New paper titled "Towards Fair Representation Learning in Knowledge Graph with Stable Adversarial Debiasing" is accepted in the ICDM workshop on Knowledge Graph. 

* Recived an [NSF Grant](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2301601&HistoricalAwards=false) to buid a safe and private AI system for health monitoring with my collaborators at UIUC and UCSD.   

* Recived an [NSF Grant](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2301599&HistoricalAwards=false) to improve fairness and robustness of AI in dynamic environmnets.


